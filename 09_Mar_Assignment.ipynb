{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with\n",
    "an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability density function (PDF) are used to describe the Probability distribution of continuos random variable It is also use calculate statics measure such as means,variance of continuos random variable\n",
    "\n",
    "    For example, suppose we are measuring the height of people in a certain population. The height can take on any value within a continuous range. The PDF for this random variable describes the relative likelihood of a person having a particular height. It might look like a bell-shaped curve, with more people having heights close to the mean and fewer people having heights further away from the mean.\n",
    "\n",
    "Probability Mass Function (PMF) are used to describe the Probability distribution of discrete random variable It is also use calculate statics measure such as means,variance of discrete random variable\n",
    "\n",
    "    For example, suppose we are rolling a fair six-sided die. The possible outcomes are 1, 2, 3, 4, 5, and 6. The PMF for this random variable is:\n",
    "\n",
    "    P(X = 1) = 1/6\n",
    "\n",
    "    P(X = 2) = 1/6\n",
    "\n",
    "    P(X = 3) = 1/6\n",
    "\n",
    "    P(X = 4) = 1/6\n",
    "\n",
    "    P(X = 5) = 1/6\n",
    "\n",
    "    P(X = 6) = 1/6\n",
    "\n",
    "    These probabilities sum to 1, as required by probability theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Cumulative Distribution Function (CDF) is a way of measuring the probability that a random variable takes on a value less than or equal to a specific value. It is a function that gives the cumulative probability of a random variable up to a certain point. The CDF is defined for both discrete and continuous random variables.\n",
    "\n",
    "For example, let's consider the case of a random variable X that represents the number of heads obtained in three coin flips. The possible values of X are 0, 1, 2, or 3. The CDF for X can be calculated as follows:\n",
    "\n",
    "F(0) = P(X <= 0) = P(X = 0) = (1/2)^3 = 1/8\n",
    "\n",
    "F(1) = P(X <= 1) = P(X = 0 or X = 1) = 1/8 + 3/8 = 1/2\n",
    "\n",
    "F(2) = P(X <= 2) = P(X = 0 or X = 1 or X = 2) = 1/8 + 3/8 + 3/8 = 7/8\n",
    "\n",
    "F(3) = P(X <= 3) = P(X = 0 or X = 1 or X = 2 or X = 3) = 1\n",
    "\n",
    "Why the CDF is a useful :\n",
    "\n",
    "    It describes the probability distribution of a random variable: The CDF provides a complete description of the probability distribution of a random variable, including the likelihood of obtaining each possible value of the variable. This makes it a valuable tool for analyzing and understanding data.\n",
    "\n",
    "    It can be used to calculate probabilities: The CDF can be used to calculate the probability of a random variable falling within a certain range of values. For example, if the CDF of a variable X is F(x), then the probability that X falls between a and b is F(b) - F(a).\n",
    "\n",
    "    It is used for hypothesis testing: In hypothesis testing, the CDF is used to calculate p-values, which measure the probability of obtaining a test statistic as extreme as the observed value, assuming the null hypothesis is true.\n",
    "\n",
    "    It can be used to compare distributions: The CDF can be used to compare the probability distribution of a random variable to a known distribution, such as the normal distribution. This can be useful for testing assumptions about the data or making probabilistic predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: What are some examples of situations where the normal distribution might be used as a model?\n",
    "Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normal distribution is a commonly used probability distribution in statistics due to its many desirable properties, such as being symmetric and bell-shaped. Here are some examples of situations where the normal distribution might be used as a model:\n",
    "\n",
    "    Heights and weights: The distribution of heights and weights in a population is often modeled using the normal distribution. This is because these variables tend to follow a bell-shaped curve around a central value.\n",
    "\n",
    "    Test scores:In educational testing, the scores of a large group of students on a standardized test are often modeled using the normal distribution. This allows us to make predictions about the likelihood of certain scores or ranges of scores.\n",
    "\n",
    "    Errors in measurements: When measuring physical quantities such as length or weight, there is always some degree of error involved. The normal distribution can be used to model the distribution of these errors, which can help in assessing the accuracy of measurements and predicting future measurements.\n",
    "\n",
    "    Financial data: Many financial data, such as stock prices or exchange rates, can exhibit a normal distribution. This can be useful for analyzing trends and making predictions about future values.\n",
    "\n",
    "    Human intelligence:IQ scores are often modeled using the normal distribution, with a mean of 100 and a standard deviation of 15. This allows us to make predictions about the likelihood of certain IQ scores and the distribution of intelligence in a population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two parameters: \n",
    "Mean (μ)  \n",
    "Standard deviation (σ)\n",
    "\n",
    "How these parameters relate to the shape of the distribution:\n",
    "\n",
    "    Mean (μ): The mean of a normal distribution is the central point around which the distribution is symmetrically distributed. It determines the location of the peak of the distribution. If the mean is increased or decreased, the entire distribution will shift to the right or left, respectively. For example, if the mean of a normal distribution is increased, the distribution will become more skewed to the right.\n",
    "\n",
    "    Standard deviation (σ): The standard deviation of a normal distribution determines the spread or variability of the data around the mean. If the standard deviation is small, the data will be tightly clustered around the mean and the distribution will be narrow. If the standard deviation is large, the data will be more spread out and the distribution will be wider. Increasing the standard deviation of a normal distribution will make it flatter and more spread out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal\n",
    "Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normal distribution is one of the most important concepts in statistics because of its many applications in the real world. Here are some reasons why the normal distribution is important:\n",
    "\n",
    "1. Many natural phenomena follow a normal distribution: The normal distribution is a mathematical representation of many natural phenomena, such as height and weight in humans, IQ scores, and even the distribution of errors in measurements. Understanding the properties of the normal distribution allows us to better understand these phenomena and make predictions about future outcomes.\n",
    "\n",
    "\n",
    "2. It allows us to make statistical inferences: The normal distribution is widely used in statistical inference, which involves making predictions or inferences about a population based on a sample of data. Many statistical tests, such as the t-test and analysis of variance (ANOVA), assume that the data follow a normal distribution in order to make accurate inferences.\n",
    "\n",
    "\n",
    "3. It provides a standard for comparison: The normal distribution provides a standard against which other distributions can be compared. For example, if we want to know whether a particular distribution of test scores is unusual, we can compare it to the normal distribution and see how far it deviates from the expected pattern.\n",
    "\n",
    "Here are a few real-life examples of normal distribution:\n",
    "\n",
    "1. IQ scores: IQ scores are normally distributed, with a mean of 100 and a standard deviation of 15. This means that most people have an IQ score between 85 and 115, and very few people have an IQ score that is much higher or lower than this range.\n",
    "\n",
    "\n",
    "2. Heights and weights: The heights and weights of humans are also normally distributed. For example, the heights of adult women in the United States are normally distributed with a mean of about 5'4\" and a standard deviation of about 2.5 inches.\n",
    "\n",
    "\n",
    "3. Stock market returns: The daily returns of many stocks and other financial instruments are approximately normally distributed. This allows investors to use statistical techniques to analyze trends and make predictions about future returns.\n",
    "\n",
    "\n",
    "4. Blood pressure: The distribution of blood pressure in a population is also normally distributed, with a mean of about 120/80 mmHg and a standard deviation of about 10-15 mmHg. This allows doctors to make predictions about the likelihood of certain blood pressure readings and diagnose hypertension based on statistical criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli\n",
    "Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bernoulli distribution is a discrete probability distribution that describes the outcome of a single binary event, such as a coin toss or a yes/no question. It is named after Swiss mathematician Jacob Bernoulli, who discovered it in the late 17th century. The distribution is characterized by a single parameter, p, which represents the probability of the event occurring.\n",
    "\n",
    "An example of Bernoulli distribution is the outcome of a single coin toss. If we assume that the coin is fair, then the probability of getting a head is p=0.5 and the probability of getting a tail is q=1-p=0.5. We can represent the outcome of a single coin toss using the Bernoulli distribution as follows:\n",
    "\n",
    "- X = 1 if the coin lands on heads (with probability p)\n",
    "- X = 0 if the coin lands on tails (with probability q)\n",
    "\n",
    "The probability mass function of the Bernoulli distribution is given by:\n",
    "\n",
    "P(X=x) = p^x * (1-p)^(1-x)    for x=0 or 1\n",
    "\n",
    "The expected value of the Bernoulli distribution is given by E(X) = p, and the variance is given by Var(X) = p(1-p).\n",
    "\n",
    "The main difference between Bernoulli distribution and binomial distribution is that Bernoulli distribution describes the outcome of a single trial, while the binomial distribution describes the outcome of multiple independent trials of a Bernoulli experiment. In other words, the Bernoulli distribution is a special case of the binomial distribution, where the number of trials is equal to 1.\n",
    "\n",
    "For example, if we toss a fair coin 10 times and count the number of heads, we can model this using a binomial distribution with n=10 trials and p=0.5 probability of success. The probability mass function of the binomial distribution is given by:\n",
    "\n",
    "P(X=k) = (n choose k) * p^k * (1-p)^(n-k)    for k=0,1,2,...,n\n",
    "\n",
    "where (n choose k) is the binomial coefficient that represents the number of ways to choose k items from a set of n items.\n",
    "\n",
    "The expected value of the binomial distribution is given by E(X) = np, and the variance is given by Var(X) = np(1-p)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset\n",
    "is normally distributed, what is the probability that a randomly selected observation will be greater\n",
    "than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The z-score is calculated as:\n",
    "\n",
    "z = (x - mu) / std\n",
    "\n",
    "where x is the value we want to find the probability for (x = 60)\n",
    "mu is the mean of the dataset (mu = 50)\n",
    "std is the standard deviation of the dataset (std = 10).\n",
    "\n",
    "we get:\n",
    "\n",
    "z = (60 - 50) / 10 = 1\n",
    "\n",
    "Now, we look up the probability of z being greater than 1 in the standard normal distribution table. The table tells us that the probability of z being greater than 1 is 0.1587.\n",
    "\n",
    "Therefore, the probability that a randomly selected observation from the given dataset will be greater than 60 is approximately 0.1587 or 15.87%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uniform distribution is a probability distribution where all possible outcomes of a random variable have equal probability of occurring.\n",
    "\n",
    "For example, suppose we have a random variable X that represents the outcome of rolling a fair six-sided die. \n",
    "Since each face of the die has an equal probability of coming up, the distribution of X is uniform, with each possible value (1, 2, 3, 4, 5, 6) having a probability of 1/6.\n",
    "\n",
    "The probability density function (PDF) of a uniform distribution is given by:\n",
    "\n",
    "f(x) = 1 / (b - a)\n",
    "\n",
    "where a is the minimum value of the distribution and b is the maximum value of the distribution. The PDF is constant between a and b and zero elsewhere.\n",
    "\n",
    "For example, suppose we have a uniform distribution with a minimum value of 0 and a maximum value of 10. The PDF of this distribution is:\n",
    "\n",
    "f(x) = 1 / (10 - 0) = 0.1\n",
    "\n",
    "for 0 ≤ x ≤ 10, and f(x) = 0 for x < 0 or x > 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The z-score tells us how far a value is from the mean in terms of standard deviations. A positive z-score indicates that the observed value is above the mean, while a negative z-score indicates that the observed value is below the mean.\n",
    "The z-score is calculated as:\n",
    "\n",
    "z = (x - mean) / std\n",
    "\n",
    " the z-score is an important statistical tool that allows us to compare values from different populations or samples and determine the probability of observing a certain value or range of values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental concept in statistics that states that as the sample size of a population increases, the distribution of sample means becomes approximately normal, regardless of the shape of the underlying population distribution. \n",
    "\n",
    "The significance of the CLT lies in its usefulness in statistical inference and hypothesis testing. The CLT allows us to make inferences about population parameters, such as the population mean, using sample means. This is important because it allows us to estimate population parameters even when we cannot directly observe or measure them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These assumptions are:\n",
    "\n",
    "    Random Sampling: The sample should be chosen randomly from the population of interest. This means that each member of the population has an equal chance of being selected for the sample.\n",
    "\n",
    "    Independence: The observations in the sample should be independent of each other. This means that the value of one observation should not affect the value of another observation.\n",
    "\n",
    "    Sample Size: The sample size should be sufficiently large. While there is no fixed rule for what constitutes a \"sufficiently large\" sample size, a general guideline is that the sample size should be at least 30.\n",
    "\n",
    "    Population Distribution: The population distribution should be either normal or approximately normal. However, even if the population distribution is not normal, the CLT can still be applied if the sample size is sufficiently large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
